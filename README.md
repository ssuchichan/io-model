# Linux I/O Model

## 概念说明
在进行解释之前，首先要说明几个概念:
* 用户空间和内核空间
* 进程切换
* 进程的阻塞
* 文件描述符
* 缓存`I/O`
* 同步(`Sync`)/异步(`Async`)
* 阻塞(`Block`)/非阻塞(`Non-block`)
* 对象的阻塞模式和阻塞函数调用

### 用户空间与内核空间
现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为`4G`（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，
可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（`kernel`），保证内核的安全，操心系统将虚拟空间划分为两部分，
一部分为内核空间，一部分为用户空间。针对`Linux`操作系统而言，将最高的1G字节（从虚拟地址`0xC0000000`到`0xFFFFFFFF`），供内核使用，称为内核空间，
而将较低的`3G`字节（从虚拟地址`0x00000000`到`0xBFFFFFFF`），供各个进程使用，称为用户空间。

### 进程切换
为了控制进程的执行，内核必须有能力挂起正在`CPU`上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，
任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。

从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：
* 1.保存处理机上下文，包括程序计数器和其他寄存器。
* 2.更新`PCB`信息。
* 3.把进程的`PCB`移入相应的队列，如就绪、在某事件阻塞等队列。
* 4.选择另一个进程执行，并更新其`PCB`。
* 5.更新内存管理的数据结构。
* 6.恢复处理机上下文。

注：总而言之就是很耗资源。

### 进程的阻塞
正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(`Block`)，
使自己由运行状态变为阻塞状态。 可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得`CPU`），才可能将其转为阻塞状态。
当进程进入阻塞状态，是不占用`CPU`资源的。


### 文件描述符(FILE DESCRIPTOR)
文件描述符（`File descriptor`）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。

文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，
内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于`UNIX`、`Linux`这样的操作系统。

在网络中，一个`socket`对象就是1个文件描述符，在文件中，1个文件句柄（即`file`对象）就是1个文件描述符。其实可以理解为就是一个“指针”或“句柄”，
指向1个`socket`或`file`对象，当file或`socket`发生改变时，这个对象对应的文件描述符，也会发生相应改变。

### 缓存I/O
缓存`I/O`又被称作标准`I/O`，大多数文件系统的默认`I/O`操作都是缓存`I/O`。在`Linux`的缓存`I/O`机制中，操作系统会将`I/O`的数据缓存在文件系统的页缓存（`page cache`）中，
也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。

缓存`I/O`的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的`CPU`以及内存开销是非常大的。

### 同步(Sync)/异步(Async)
同步/异步主要针对客户端:

同步：所谓同步，就是在客户端发出一个功能调用时，在没有得到结果之前，该调用就不返回。也就是必须一件一件事做,等前一件做完了才能做下一件事。
例如普通B/S模式（同步）：提交请求->等待服务器处理->处理完毕返回 这个期间客户端浏览器不能干任何事。

异步：异步的概念和同步相对。当客户端一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。
例如`ajax`请求（异步）: 请求通过事件触发->服务器处理（这是浏览器仍然可以作其他事情）->处理完毕。

### 阻塞(Block)/非阻塞(Non-block)
阻塞/非阻塞主要针对S端

阻塞：

阻塞调用是指调用结果返回之前，当前线程会被挂起（线程进入非可执行状态，在这个状态下，`CPU`不会给线程分配时间片，即线程暂停运行）。函数只有在得到结果之后才会返回。
有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回而已。 例如，
我们在`socket`中调用`recv`函数，如果缓冲区中没有数据，这个函数就会一直等待，直到有数据才返回。而此时，当前线程还会继续处理各种各样的消息。
快递的例子：比如到你某个时候到A楼一层（假如是内核缓冲区）取快递，但是你不知道快递什么时候过来，你又不能干别的事，只能死等着。
但你可以睡觉（进程处于休眠状态），因为你知道快递把货送来时一定会给你打个电话（假定一定能叫醒你）。

非阻塞：

非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。
还是等快递的例子：如果用忙轮询的方法，每隔5分钟到A楼一层(内核缓冲区）去看快递来了没有。如果没来，立即返回。而快递来了，就放在A楼一层，等你去取。

### 对象的阻塞模式和阻塞函数调用
对象是否处于阻塞模式和函数是不是阻塞调用有很强的相关性，但是并不是一一对应的。阻塞对象上可以有非阻塞的调用方式，我们可以通过一定的API去轮询状态，
在适当的时候调用阻塞函数，就可以避免阻塞。而对于非阻塞对象，调用特殊的函数也可以进入阻塞调用。函数`select`就是这样的一个例子。

1. 同步，就是我客户端（客户端调用者）调用一个功能，该功能没有结束前，我（客户端调用者）死等结果。
2. 异步，就是我（客户端调用者）调用一个功能，不需要知道该功能结果，该功能有结果后通知我（客户端调用者）即回调通知。同步/异步主要针对客户端, 但是跟服务端不是完全没有关系，同步/异步机制必须服务端配合才能实现.同步/异步是由客户端自己控制,但是服务端是否阻塞/非阻塞, 客户端完全不需要关心。   
3. 阻塞，就是调用我（服务端被调用者，函数），我（服务端被调用者，函数）没有接收完数据或者没有得到结果之前，我不会返回。
4. 非阻塞，就是调用我（服务端被调用者，函数），我（服务端被调用者，函数）立即返回，通过`select`通知调用者。

同步和异步都只针对于本机`socket`而言的。同步和异步,阻塞和非阻塞,有些混用,其实它们完全不是一回事,而且它们修饰的对象也不相同。

阻塞和非阻塞是指当服务端的进程访问的数据如果尚未就绪,进程是否需要等待,简单说这相当于函数内部的实现区别,也就是未就绪时是直接返回还是等待就绪;

而同步和异步是指客户端访问数据的机制,同步一般指主动请求并等待`I/O`操作完毕的方式,当数据就绪后在读写的时候必须阻塞(区别就绪与读写二个阶段,同步的读写必须阻塞),
异步则指主动请求数据后便可以继续处理其它任务,随后等待`I/O`,操作完毕的通知,这可以使进程在数据读写时也不阻塞。(等待"通知")

总结:

同步`I/O`和异步`I/O`的区别就在于：数据访问的时候进程是否阻塞！ 

阻塞`I/O`和非阻塞`I/O`的区别就在于：应用程序的调用是否立即返回！


## I/O模式
对于一次`I/O`访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：
* 等待数据准备 (Waiting for the data to be ready)
* 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)

正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。
- 阻塞`I/O`（`blocking I/O`）
- 非阻塞`I/O`（`non-blocking I/O`）
- `I/O`多路复用（`IO multiplexing`）
- 信号驱动`I/O`（`signal driven I/O`）
- 异步`I/O`（`asynchronous I/O`）

注：由于`signal driven I/O`在实际中并不常用，所以我这只提及剩下的四种`I/O Model`。前四种都是同步，只有最后一种才是异步IO。

### 阻塞I/O
在`Linux`中，默认情况下所有的`socket`都是`blocking`，进程会一直阻塞，直到数据拷贝完成，一个典型的读操作流程大概是这样：
当用户进程调用了`recvfrom`这个系统调用，`kernel`就开始了`I/O`的第一个阶段：准备数据（对于网络`I/O`来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的`UDP`包。
这个时候`kernel`就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。
当`kernel`一直等到数据准备好了，它就会将数据从`kernel`中拷贝到用户内存，然后`kernel`返回结果，用户进程才解除`block`的状态，重新运行起来。

所以，阻塞 IO的特点就是在IO执行的两个阶段都被阻塞了。

### 非阻塞I/O
`Linux`下，可以通过设置`socket`使其变为`non-blocking`。当对一个`non-blocking socket`执行读操作时，流程是这个样子：

当用户进程发出`read`操作时，如果`kernel`中的数据还没有准备好，那么它并不会`block`用户进程，而是立刻返回一个`error`。从用户进程角度讲，它发起一个`read`操作后，
并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个`error`时， 它就知道数据还没有准备好，于是它可以再次发送`read`操作。一旦`kernel`中的数据准备好了，
并且又再次收到了用户进程的`system call`，那么它马上就将数据拷贝到了用户内存，然后返回。

所以，`non-blocking I/O`的特点是用户进程需要不断的主动询问kernel数据好了没有。已经可以实现多并发，从内核态拷贝到用户态还有堵塞。

优点：等待数据过程中，无阻塞。（拷贝数据过程中，处于阻塞）

缺点：系统调用太多，数据不是实时接受的。

### I/O多路复用（IO multiplexing）
`IO multiplexing`就是我们说的`select`，`poll`，`epoll`，有些地方也称这种`IO`方式为`event driven IO`。`select/epoll`的好处就在于单个进程就可以同时处理多个网络连接的`I/O`。
它的基本原理就是`select`，`poll`，`epoll`这个function会不断的轮询所负责的所有`socket`，当某个`socket`有数据到达了，就通知用户进程。

当用户进程调用了`select`，那么整个进程会被`block`，而同时，`kernel`会“监视”所有`select`负责的`socket`，当任何一个`socket`中的数据准备好了，`select`就会返回。
这个时候用户进程再调用`read`操作，将数据从`kernel`拷贝到用户进程。所以，`I/O`多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，
而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，`select`函数就可以返回。

这个图和`blocking I/O`的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个`system call`(`select`和`recvfrom`)，而`blocking IO`只调用了一个`system call` (`recvfrom`)。
但是，用`select`的优势在于它可以同时处理多个连接。

所以，如果处理的连接数不是很高的话，使用`select/epoll`的`web server`不一定比使用`multi-threading + blocking IO`的`web server`性能更好，可能延迟还更大。
`select/epoll`的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）

在`IO multiplexing Model`中，实际中，对于每一个socket，一般都设置成为`non-blocking`，但是，如上图所示，整个用户的连接其实是一直被`block`的。
只不过进程是被`select`这个函数`block`，而不是被`socket I/O`给`block`。

### 异步I/O（asynchronous IO）
`Linux`下的`asynchronous I/O`其实用得很少。先看一下它的流程:

用户进程发起`read`操作之后，立刻就可以开始去做其它的事。而另一方面，从`kernel`的角度，当它受到一个`asynchronous read`之后，首先它会立刻返回，
所以不会对用户进程产生任何`block`。然后，`kernel`会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，`kernel`会给用户进程发送一个信号，
告诉它`read`操作完成了。

## 总结
`blocking`和`non-blocking`的区别： 调用`blocking I/O`会一直`block`住对应的进程直到操作完成，而`non-blocking I/O`在`kernel`还准备数据的情况下会立刻返回。

`synchronous I/O`和`asynchronous I/O`的区别：两者的区别就在于`synchronous I/O`做`I/O operation`的时候会将进程阻塞。按照这个定义，
之前所述的`blocking I/O`，`non-blocking I/O`，`I/O multiplexing`都属于`synchronous I/O`。

有人会说，`non-blocking I/O`并没有被`block`啊。这里有个非常“狡猾”的地方，定义中所指的`I/O operation`是指真实的`I/O`操作，就是例子中的`recvfrom`这个`system call`。
`non-blocking I/O`在执行`recvfrom`这个`system call`的时候，如果`kernel`的数据没有准备好，这时候不会`block`进程。但是，当`kernel`中数据准备好的时候，
`recvfrom`会将数据从`kernel`拷贝到用户内存中，这个时候进程是被`block`了，在这段时间内，进程是被`block`的。

而`asynchronous I/O`则不一样，当进程发起`I/O`操作之后，就直接返回再也不理睬了，直到`kernel`发送一个信号，告诉进程说`I/O`完成。在这整个过程中，进程完全没有被`block`。

各个`I/O`模型比较：

通过上面的图片，可以发现`non-blocking I/O`和`asynchronous I/O`的区别还是很明显的。在`non-blocking I/O`中，虽然进程大部分时间都不会被`block`，
但是它仍然要求进程去主动的检查，并且当数据准备完成以后，也需要进程主动的再次调用`recvfrom`来将数据拷贝到用户内存。而`asynchronous I/O`则完全不同。
它就像是用户进程将整个`I/O`操作交给了他人（`kernel`）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查`I/O`操作的状态，也不需要主动的去拷贝数据。


















